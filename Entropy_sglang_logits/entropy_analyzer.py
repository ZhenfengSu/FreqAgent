import json
import re
import numpy as np
import requests
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from tqdm import tqdm
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


@dataclass
class PhaseEntropy:
    """å­˜å‚¨æŸä¸ªPhaseçš„ç†µç»Ÿè®¡ç»“æœ"""
    phase_name: str
    entropies: List[float] = field(default_factory=list)
    token_count: int = 0
    
    @property
    def average_entropy(self) -> float:
        if not self.entropies:
            return 0.0
        return float(np.mean(self.entropies))
    
    @property
    def std_entropy(self) -> float:
        if len(self.entropies) < 2:
            return 0.0
        return float(np.std(self.entropies))
    
    def add_entropies(self, entropies: List[float]):
        self.entropies.extend(entropies)
        self.token_count += len(entropies)


class SGLangEntropyAnalyzer:
    """ä½¿ç”¨ sglang API è¿›è¡Œç†µç»Ÿè®¡åˆ†æ"""
    
    def __init__(self, base_url: str = "http://localhost:6001"):
        self.base_url = base_url.rstrip('/')
        self.model_name = self._get_model_name()
        
        # Phaseæ ‡è®°æ­£åˆ™è¡¨è¾¾å¼
        self.phase_patterns = {
            'think': re.compile(r'<think>(.*?)</think>', re.DOTALL),
            'tool_call': re.compile(r'<tool_call>(.*?)</tool_call>', re.DOTALL),
            'tool_response': re.compile(r'<tool_response>(.*?)</tool_response>', re.DOTALL),
            'answer': re.compile(r'<answer>(.*?)</answer>', re.DOTALL),
        }
        
        logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {self.model_name}")
    
    def _get_model_name(self) -> str:
        """è·å–æ¨¡å‹åç§°"""
        try:
            response = requests.get(f"{self.base_url}/v1/models", timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('data'):
                    return data['data'][0]['id']
        except Exception as e:
            logger.warning(f"è·å–æ¨¡å‹åç§°å¤±è´¥: {e}")
        return "default"
    
    def calculate_entropy_from_top_logprobs(self, top_logprobs_dict: Dict[str, float]) -> float:
        """ä» top_logprobs å­—å…¸è®¡ç®—ç†µ"""
        if not top_logprobs_dict:
            return 0.0
        
        logprobs = list(top_logprobs_dict.values())
        probs = np.exp(np.array(logprobs, dtype=np.float64))
        
        prob_sum = probs.sum()
        if prob_sum <= 0:
            return 0.0
        probs = probs / prob_sum
        
        entropy = -np.sum(probs * np.log(probs + 1e-10))
        return float(entropy)
    
    def get_completion_with_logprobs(self, prompt: str, max_tokens: int = 1024) -> Optional[Dict]:
        """è·å– completion å’Œ logprobs"""
        url = f"{self.base_url}/v1/completions"
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "max_tokens": max_tokens,
            "temperature": 0,
            "logprobs": 10,
        }
        
        try:
            response = requests.post(url, json=payload, timeout=300)
            
            if response.status_code == 200:
                result = response.json()
                return self._parse_response(result)
            else:
                logger.warning(f"APIè¿”å›é”™è¯¯ {response.status_code}: {response.text[:200]}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("è¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def _parse_response(self, result: Dict) -> Optional[Dict]:
        """è§£æ API å“åº”"""
        if 'choices' not in result or len(result['choices']) == 0:
            return None
        
        choice = result['choices'][0]
        logprobs_data = choice.get('logprobs', {})
        
        return {
            'text': choice.get('text', ''),
            'tokens': logprobs_data.get('tokens', []),
            'token_logprobs': logprobs_data.get('token_logprobs', []),
            'top_logprobs': logprobs_data.get('top_logprobs', []),
        }
    
    def compute_token_entropies(self, top_logprobs: List[Dict[str, float]]) -> List[float]:
        """è®¡ç®—æ¯ä¸ª token ä½ç½®çš„ç†µ"""
        entropies = []
        for top_lp in top_logprobs:
            if top_lp is None or not isinstance(top_lp, dict):
                entropies.append(0.0)
                continue
            entropy = self.calculate_entropy_from_top_logprobs(top_lp)
            entropies.append(entropy)
        return entropies
    
    def extract_phases_with_token_ranges(
        self,
        content: str,
        tokens: List[str]
    ) -> Dict[str, List[Tuple[int, int]]]:
        """
        æå–å„ä¸ª phase å¯¹åº”çš„ token ç´¢å¼•èŒƒå›´
        è¿”å›: {phase_name: [(start_token_idx, end_token_idx), ...]}
        """
        phases = {phase: [] for phase in self.phase_patterns.keys()}
        
        if not tokens:
            return phases
        
        # é‡å»º token çš„å­—ç¬¦ä½ç½®æ˜ å°„
        token_char_positions = []  # [(char_start, char_end), ...]
        current_pos = 0
        
        for token in tokens:
            token_start = current_pos
            token_end = current_pos + len(token)
            token_char_positions.append((token_start, token_end))
            current_pos = token_end
        
        # å¯¹æ¯ä¸ª phase patternï¼Œæ‰¾åˆ°å…¶åœ¨ content ä¸­çš„å­—ç¬¦èŒƒå›´
        for phase_name, pattern in self.phase_patterns.items():
            for match in pattern.finditer(content):
                # æ ‡ç­¾å†…éƒ¨å†…å®¹çš„å­—ç¬¦ä½ç½®
                tag_open = f'<{phase_name}>'
                tag_close = f'</{phase_name}>'
                inner_char_start = match.start() + len(tag_open)
                inner_char_end = match.end() - len(tag_close)
                
                # æ‰¾åˆ°å¯¹åº”çš„ token èŒƒå›´
                start_token_idx = None
                end_token_idx = None
                
                for i, (t_start, t_end) in enumerate(token_char_positions):
                    # token ä¸ phase å†…å®¹æœ‰äº¤é›†
                    if t_end > inner_char_start and t_start < inner_char_end:
                        if start_token_idx is None:
                            start_token_idx = i
                        end_token_idx = i + 1
                
                if start_token_idx is not None:
                    phases[phase_name].append((start_token_idx, end_token_idx))
        
        return phases
    
    def build_prompt_for_message(self, messages: List[Dict], target_msg_idx: int) -> str:
        """
        æ„å»ºç”¨äºè®©æ¨¡å‹ç»­å†™ç¬¬ target_msg_idx ä¸ª message çš„ prompt
        """
        prompt_parts = []
        
        for i, msg in enumerate(messages):
            if i >= target_msg_idx:
                break
            
            role = msg.get('role', '')
            content = msg.get('content', '')
            prompt_parts.append(f"<|im_start|>{role}\n{content}<|im_end|>")
        
        # æ·»åŠ ç›®æ ‡ message çš„å¼€å¤´
        target_role = messages[target_msg_idx].get('role', 'assistant')
        prompt_parts.append(f"<|im_start|>{target_role}\n")
        
        return "\n".join(prompt_parts)
    
    def analyze_single_sample(self, messages: List[Dict]) -> Dict[str, List[float]]:
        """åˆ†æå•ä¸ªæ ·æœ¬ä¸­æ‰€æœ‰ assistant ç”Ÿæˆçš„å†…å®¹"""
        all_phase_entropies = {phase: [] for phase in self.phase_patterns.keys()}
        
        for msg_idx, msg in enumerate(messages):
            role = msg.get('role', '')
            content = msg.get('content', '')
            
            if not content or len(content) < 5:
                continue
            
            # æ£€æµ‹è¿™ä¸ª message ä¸­æœ‰å“ªäº› phase
            detected_phases = []
            for phase_name, pattern in self.phase_patterns.items():
                if pattern.search(content):
                    detected_phases.append(phase_name)
            
            if not detected_phases:
                logger.debug(f"Message {msg_idx} (role={role}): æœªæ£€æµ‹åˆ°ä»»ä½• phase æ ‡ç­¾ï¼Œè·³è¿‡")
                continue
            
            logger.info(f"Message {msg_idx} (role={role}): æ£€æµ‹åˆ° phases: {detected_phases}")
            logger.debug(f"  Content preview: {content[:100]}...")
            
            # æ„å»º prompt
            prompt = self.build_prompt_for_message(messages, msg_idx)
            
            # ä¼°ç®—éœ€è¦ç”Ÿæˆçš„ token æ•°
            estimated_tokens = int(len(content) * 1.5)
            max_gen_tokens = min(max(estimated_tokens, 512), 8192)
            
            # è·å– logprobs
            result = self.get_completion_with_logprobs(prompt, max_tokens=max_gen_tokens)
            
            if result is None:
                logger.warning(f"è·å– logprobs å¤±è´¥ï¼Œè·³è¿‡ message {msg_idx}")
                continue
            
            tokens = result.get('tokens', [])
            top_logprobs = result.get('top_logprobs', [])
            
            if not tokens or not top_logprobs:
                logger.warning(f"Message {msg_idx}: tokens æˆ– logprobs ä¸ºç©º")
                continue
            
            # è®¡ç®—æ¯ä¸ª token çš„ç†µ
            token_entropies = self.compute_token_entropies(top_logprobs)
            
            # é‡å»ºç”Ÿæˆçš„æ–‡æœ¬
            generated_text = ''.join(tokens)
            
            logger.info(f"Message {msg_idx}: ç”Ÿæˆäº† {len(tokens)} ä¸ª tokens")
            logger.debug(f"  åŸå§‹ content é•¿åº¦: {len(content)}")
            logger.debug(f"  ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(generated_text)}")
            logger.debug(f"  ç”Ÿæˆæ–‡æœ¬é¢„è§ˆ: {generated_text[:150]}...")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«é¢„æœŸçš„ phase
            gen_detected = []
            for phase_name, pattern in self.phase_patterns.items():
                if pattern.search(generated_text):
                    gen_detected.append(phase_name)
            logger.info(f"  ç”Ÿæˆæ–‡æœ¬ä¸­æ£€æµ‹åˆ°çš„ phases: {gen_detected}")
            
            # åœ¨ç”Ÿæˆçš„æ–‡æœ¬ä¸­å®šä½ phases
            phase_token_ranges = self.extract_phases_with_token_ranges(generated_text, tokens)
            
            # æ”¶é›†æ¯ä¸ª phase çš„ç†µ
            for phase_name, ranges in phase_token_ranges.items():
                for start_idx, end_idx in ranges:
                    phase_entropies = token_entropies[start_idx:end_idx]
                    all_phase_entropies[phase_name].extend(phase_entropies)
                    
                    if phase_entropies:
                        logger.info(
                            f"  Phase '{phase_name}': tokens[{start_idx}:{end_idx}] = {end_idx - start_idx} tokens, "
                            f"avg_entropy={np.mean(phase_entropies):.4f}"
                        )
        
        return all_phase_entropies
    
    def analyze_dataset(self, data: List[Dict], max_samples: int = None) -> Dict[str, PhaseEntropy]:
        """åˆ†ææ•´ä¸ªæ•°æ®é›†"""
        phase_stats = {
            'think': PhaseEntropy('Think Phase (æ€è€ƒé˜¶æ®µ)'),
            'tool_call': PhaseEntropy('Action Phase (å·¥å…·è°ƒç”¨)'),
            'tool_response': PhaseEntropy('Tool Response (å·¥å…·å“åº”)'),
            'answer': PhaseEntropy('Answer Phase (å›ç­”é˜¶æ®µ)'),
        }
        
        samples = data[:max_samples] if max_samples else data
        logger.info(f"å¼€å§‹åˆ†æ {len(samples)} ä¸ªæ ·æœ¬...")
        
        successful = 0
        for sample in tqdm(samples, desc="åˆ†æè¿›åº¦"):
            messages = sample.get('messages', [])
            if not messages:
                continue
            
            try:
                sample_entropies = self.analyze_single_sample(messages)
                
                has_data = False
                for phase_name, entropies in sample_entropies.items():
                    if entropies:
                        phase_stats[phase_name].add_entropies(entropies)
                        has_data = True
                
                if has_data:
                    successful += 1
                        
            except Exception as e:
                logger.warning(f"æ ·æœ¬åˆ†æå‡ºé”™: {e}")
                import traceback
                logger.debug(traceback.format_exc())
                continue
        
        logger.info(f"æˆåŠŸåˆ†æ {successful}/{len(samples)} ä¸ªæ ·æœ¬")
        return phase_stats
    
    def print_results(self, phase_stats: Dict[str, PhaseEntropy]):
        """æ‰“å°ç»“æœ"""
        print("\n" + "=" * 70)
        print("            ç†µç»Ÿè®¡åˆ†æç»“æœ (Entropy Analysis Results)")
        print("=" * 70)
        
        for phase_name, stats in phase_stats.items():
            print(f"\nğŸ“Š ã€{stats.phase_name}ã€‘")
            print(f"   â”œâ”€ Tokenæ•°é‡:      {stats.token_count:,}")
            print(f"   â”œâ”€ å¹³å‡ç†µ (Avg):   {stats.average_entropy:.4f}")
            print(f"   â”œâ”€ æ ‡å‡†å·® (Std):   {stats.std_entropy:.4f}")
            if stats.entropies:
                print(f"   â”œâ”€ æœ€å°ç†µ (Min):   {min(stats.entropies):.4f}")
                print(f"   â”œâ”€ æœ€å¤§ç†µ (Max):   {max(stats.entropies):.4f}")
                print(f"   â””â”€ ä¸­ä½æ•° (Med):   {float(np.median(stats.entropies)):.4f}")
            else:
                print(f"   â””â”€ (æ— æ•°æ®)")
        
        print("\n" + "=" * 70)
    
    def save_results(self, phase_stats: Dict[str, PhaseEntropy], output_path: str):
        """ä¿å­˜ç»“æœåˆ° JSON"""
        results = {
            'summary': {},
            'details': {}
        }
        
        for phase_name, stats in phase_stats.items():
            results['details'][phase_name] = {
                'phase_name': stats.phase_name,
                'token_count': stats.token_count,
                'average_entropy': stats.average_entropy,
                'std_entropy': stats.std_entropy,
            }
            results['summary'][phase_name] = {
                'avg_entropy': stats.average_entropy,
                'token_count': stats.token_count
            }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def diagnose_data(input_path: str):
    """è¯Šæ–­æ•°æ®æ–‡ä»¶ä¸­çš„ phase åˆ†å¸ƒ"""
    print("\n" + "=" * 70)
    print("ğŸ” æ•°æ®è¯Šæ–­")
    print("=" * 70)
    
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"\nğŸ“‚ æ–‡ä»¶: {input_path}")
    print(f"ğŸ“Š æ ·æœ¬æ€»æ•°: {len(data)}")
    
    phase_patterns = {
        'think': re.compile(r'<think>(.*?)</think>', re.DOTALL),
        'tool_call': re.compile(r'<tool_call>(.*?)</tool_call>', re.DOTALL),
        'tool_response': re.compile(r'<tool_response>(.*?)</tool_response>', re.DOTALL),
        'answer': re.compile(r'<answer>(.*?)</answer>', re.DOTALL),
    }
    
    # ç»Ÿè®¡å„ role å’Œ phase çš„åˆ†å¸ƒ
    role_counts = {}
    phase_by_role = {phase: {} for phase in phase_patterns.keys()}
    
    for sample_idx, sample in enumerate(data[:10]):  # åªçœ‹å‰10ä¸ªæ ·æœ¬
        messages = sample.get('messages', [])
        
        print(f"\n--- Sample {sample_idx} ({len(messages)} messages) ---")
        
        for msg_idx, msg in enumerate(messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')
            
            role_counts[role] = role_counts.get(role, 0) + 1
            
            detected = []
            for phase_name, pattern in phase_patterns.items():
                matches = pattern.findall(content)
                if matches:
                    detected.append(f"{phase_name}({len(matches)})")
                    phase_by_role[phase_name][role] = phase_by_role[phase_name].get(role, 0) + len(matches)
            
            if detected or role == 'assistant':
                content_preview = content[:60].replace('\n', 'â†µ') if content else "(empty)"
                print(f"  [{msg_idx}] role={role:10s} phases={detected or 'none':30s} | {content_preview}...")
    
    print("\n" + "-" * 70)
    print("ğŸ“ˆ Phase åˆ†å¸ƒæŒ‰ Role ç»Ÿè®¡ (å‰10ä¸ªæ ·æœ¬):")
    for phase_name, role_dist in phase_by_role.items():
        print(f"  {phase_name:15s}: {role_dist}")
    
    print("\nğŸ’¡ å¦‚æœ tool_response åªå‡ºç°åœ¨é assistant roleï¼Œéœ€è¦è°ƒæ•´ä»£ç é€»è¾‘")
    print("=" * 70)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Agent ç†µç»Ÿè®¡åˆ†æå·¥å…·')
    parser.add_argument('--input', '-i', type=str, help='è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, default='entropy_results.json', help='è¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--base-url', type=str, default='http://localhost:6001', help='sglang æœåŠ¡åœ°å€')
    parser.add_argument('--limit', type=int, default=None, help='é™åˆ¶æ ·æœ¬æ•°é‡')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯• API è¿æ¥')
    parser.add_argument('--diagnose', action='store_true', help='è¯Šæ–­æ•°æ®æ–‡ä»¶ä¸­çš„ phase åˆ†å¸ƒ')
    parser.add_argument('--debug', action='store_true', help='æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    if args.diagnose and args.input:
        diagnose_data(args.input)
        return
    
    if args.test:
        analyzer = SGLangEntropyAnalyzer(args.base_url)
        result = analyzer.get_completion_with_logprobs("Hello", max_tokens=5)
        if result:
            print("âœ… API è¿æ¥æˆåŠŸ")
            print(f"   ç”Ÿæˆ: {result['text']}")
        else:
            print("âŒ API è¿æ¥å¤±è´¥")
        return
    
    if not args.input:
        print("ç”¨æ³•:")
        print("  è¯Šæ–­æ•°æ®:  python script.py --diagnose -i data.json")
        print("  è¿è¡Œåˆ†æ:  python script.py -i data.json --debug --limit 2")
        return
    
    # è¿è¡Œåˆ†æ
    with open(args.input, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    analyzer = SGLangEntropyAnalyzer(args.base_url)
    phase_stats = analyzer.analyze_dataset(data, max_samples=args.limit)
    
    analyzer.print_results(phase_stats)
    analyzer.save_results(phase_stats, args.output)


if __name__ == '__main__':
    main()